[
  {
    "objectID": "another-page.html",
    "href": "another-page.html",
    "title": "Term Frequency - Inverse Document Frequency Analysis",
    "section": "",
    "text": "Term Frequency - Inverse Document Frequency (TF-IDF) is a measure of how important a word is in a document, adjusted for the fact that some words appear more frequently in general. In colloquial terms, the TF-IDF of a word is high when it appears frequently in a document but rarely in the corpus (collection of all documents)."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Which NESCAC Reigns Supreme?",
    "section": "",
    "text": "What’s going on here?\n\n\n\n\n\n\n\n\nFigure 1: Most common words across all subreddits\n\n\n\n\n\nIf you are unfamiliar with Reddit.com, we may have to begin by inquiring about the rock you’ve been living under for nigh-on two decades. In all seriousness (don’t stop reading, we’re sorry), along with X, the forum-based social media platform is a primary hub for commentary on any issue you could think of (for better or for worse). It is this plethora of unfiltered content that makes Reddit a commonly visited site for web scrapers and data scientist nerds alike with a variety of goals including but not limited to: theme and topic discovery, sentiment and engagement analysis, and user activity research. Our current data science project is spurred by similar motivations; we look to extract key topics and conduct sentiment analysis (positive or negative valence of a text) for three individual subreddits: Amherst College, Middlebury College, and Williams College. Specifically, we aim to compare the sentiments meaningfully of each subreddit, as both a per-post average and a totality, examine temporal trends in sentiment and comment engagement, extract the most frequently discussed topics, and, because we are looking at colleges here, and track mentions of the admissions process.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYou may be wondering why we picked these specific subreddits and what this project can tell us in the grand scheme of things. As students at Amherst College, we thought it would be particularly fun to compare our own subreddit to that of some of our least favorite sister schools in the NESCAC. On a more practical basis, these three subreddits were small enough for us to be able to scrape all posts until January 2020 with no issues. In regards to our purpose, even if you are not a current student in the NESCAC who may get a kick out of pitting Amherst, Middlebury, and Williams against each other, our analysis provides insights into what is being discussed and prioritized at these different institutions, along with an assessment of their varying levels of positivity. We think of prospective students as one group who might be interested in our results, as well as anyone curious about the state of the small liberal arts colleges (at least from Reddit’s perspective).\n\n\nRedditExtractoR\nWeb scraping is a notoriously error-laden path. As websites increasingly deploy dynamically rendered data and IP address blocking, it has never been harder to get the data you want. Luckily, we found a tool that could scrape up to 1000 posts per request. The Rivera (2025) RedditExtractoR scraping package gives a post’s title, content, number of comments, and date, all in as little as 3 lines of R code:\n\nlibrary(RedditExtractoR)\namherst_posts_raw &lt;- find_thread_urls(\n  subreddit = \"amherstcollege\", sort_by = \"new\", period = \"day\")\n\n\n\nMethods for Sentiment Analysis\nOnce we scraped each subreddit, we joined all the posts into one big dataset and assigned a sentiment score to the content of each post. This score was calculated using the Afinn Lexicon, which maps words to integer values between -5 and 5 based on their positive-negative valence (for more information, see Zhang (n.d.)). The score for each post simply became the sum of the sentiments for the words that comprised it. Further documentation of our methods will be laid out as we delve into our specific efforts below, but if you want to explore the general dataset that we created and used throughout the project, see Figure 2 at the end of this blog. What you are seeing here are the results of recent, applicable, and primary-sourced data!\n\n\nRaw Data Reference\n\n\n\n\n\n\n\n\nFigure 2: Our scraped data: all subreddit posts\n\n\n\n\n\n\n\n\n\nReferences\n\nRivera, I. (2025), “Ivan-rivera/RedditExtractor,” R,.\n\n\nZhang, Z. (n.d.). Text mining for social and behavioral research using r."
  },
  {
    "objectID": "index.html#website-project-structure",
    "href": "index.html#website-project-structure",
    "title": "Which NESCAC Reigns Supreme?",
    "section": "Website project structure",
    "text": "Website project structure\nThe website project folder/repo will contain the following files, at a minimum:\n\n_quarto.yml: A configuration file that controls the YAML content, similar to what we typically see at the top of our qmd files.\nUse this file to add or remove additional subpages, change the overall website title, customize the navigation bar contents and layout, change the website theme, and set any other default formatting options such as code chunk options.\nindex.qmd: This is the landing page of your website. This file must be called index.qmd and must be located in the root directory of the project.\nUse this page, at a minimum, to introduce your project. From there you can either fully include the contents of the project or use additional qmd files to create subpages of your website (perhaps explaining the structure of the website to the user on this landing page).\nbib folder: Contains the bibliography file, which you should edit to include your resources, and a .csl file that tells Quarto how to format in-text citations and the bibliography list according to the American Statistical Association citation style.\ndocs folder: The rendered content of the website will be located here.\nstyles.css: This file is currently empty, but if you want to modify or replace the default theme, do so here using CSS. Students in the past have used custom color palettes or custom fonts, for example.\nAdditional qmd files: If you want to add subpages with their own content, create new qmd files in your root directory to do so, being sure to include them in the list of contents in your _quarto.yml file.\n\n\nOther recommended content:\nSimilar to the Shiny project, you will need to organize your wrangling scripts and data. You may also have other images or figures saved for displaying in your blog that will also need to be organized. Here are recommendations for organization.\n\nscripts: Store wrangling scripts in their own folder\ndata: Store datasets in their own folder, being sure to separate raw data from clean/processed data. You can do this in one of two ways: two separate data folders in the root directory (e.g., raw-data and data) or two subfolders of a single data folder (subfolders called, for example, raw, processed).\nimages: Organize saved images or figures together in their own folder. Make sure you keep track of the source of the images or figures and credit the sources in some way in your page (include source in caption and/or link image to source)"
  },
  {
    "objectID": "index.html#workflow",
    "href": "index.html#workflow",
    "title": "Which NESCAC Reigns Supreme?",
    "section": "Workflow",
    "text": "Workflow\n\nEdit contents of any files. Each new qmd file is a self-contained environment, so you will need to load any necessary packages and datasets for rendering that particular file at the top of that file.\nAfter updating a qmd file, Render the qmd file. Note that the rendered files (.html etc) are in the docs folder. Keep them there!\nCommit changes to website and PUSH to publish those changes."
  },
  {
    "objectID": "index.html#cross-referencing",
    "href": "index.html#cross-referencing",
    "title": "Which NESCAC Reigns Supreme?",
    "section": "Cross-referencing",
    "text": "Cross-referencing\nYou should use code chunk labels and in-text cross-references for figures and tables (see the Knitr examples at the link).\nQuarto additionally provides similar syntax for creating labels for and cross-referencing equations, creating labels for and cross-referencing sections, and using code chunk options of the form lst-label: lst-your-listing-label and lst-cap: Code chunk caption to be able to cross-reference displayed code chunks (or “listings”) using the syntax @lst-your-listing-label within the text.\nThese are not required for this project but are good practice."
  },
  {
    "objectID": "index.html#creating-and-linking-to-subpages",
    "href": "index.html#creating-and-linking-to-subpages",
    "title": "Which NESCAC Reigns Supreme?",
    "section": "Creating and linking to subpages",
    "text": "Creating and linking to subpages\nYou can create subpages by simply creating new qmd files. Any subpage you want to include on the website should be added to the website navigation list in the _quarto.yml file.\nYou can link to another page on the website by using just the filepath to the corresponding qmd file. You can also link directly to a section of a subpage."
  },
  {
    "objectID": "index.html#creating-the-bibliography",
    "href": "index.html#creating-the-bibliography",
    "title": "Which NESCAC Reigns Supreme?",
    "section": "Creating the bibliography",
    "text": "Creating the bibliography\nOne of the new challenges of Quarto, relative to a Word or Google doc, is learning how to build a bibliography and use the specified citation keys to write in-text citations.\nAll items you plan to cite should be added to the library.bib bibliography file, which you can open from within RStudio and edit just like any other text file. You should use standard bibtex syntax for each entry, following the examples provided. If the resource you are using doesn’t already provide a way to generate a bibtex entry, I recommend using zoterobib to generate the appropriate syntax (must change the Bibliography style to “BibTeX generic citation style”). The entries currently in library.bib are intended to provide syntax examples that capture the range of entries you are most likely to use. You will need to delete and replace the contents of library.bib with your own citation entries.\n\n\n\n\n\n\nNote\n\n\n\nThe examples in library.bib are nicely formatted so you can read and follow the patterns, but formatting and order of the library.bib file doesn’t actually matter and will not be assessed. Just be sure the citations are as complete as possible (authors, titles, dates, urls, dois, etc.).\n\n\n@book{hadley2016,\n  author = {Hadley, Wickham}, \n  title = {ggplot2: Elegant Graphics for Data Analysis}, \n  url  = {https://ggplot2-book.org},\n  publisher = {Springer},\n  address = {New York, NY},\n  type = {Online book},\n  year = {2016},\n  edition = {3}\n}"
  },
  {
    "objectID": "index.html#creating-in-text-citations",
    "href": "index.html#creating-in-text-citations",
    "title": "Which NESCAC Reigns Supreme?",
    "section": "Creating in-text citations",
    "text": "Creating in-text citations\nItems you cite in the text will be automatically added to a list of References at the bottom of the corresponding page. To cite a reference in the text, use the corresponding citation key (the first item in each bibtex entry—it shouldn’t have any spaces or special characters) and format the citation using the appropriate quarto format for in-text citations. This is similar to how we cross-reference tables and figures from code chunk labels. For example, the syntax\n@hadley2016 provides excellent examples of customizing our visualizations using **ggplot2**.\nproduces the following text:\n\nHadley (2016) provides excellent examples of customizing our visualizations using ggplot2.\n\nAnd the corresponding reference is listed in full at the bottom of this page."
  },
  {
    "objectID": "index.html#including-images-or-gifs",
    "href": "index.html#including-images-or-gifs",
    "title": "Which NESCAC Reigns Supreme?",
    "section": "Including images or gifs",
    "text": "Including images or gifs\nI would strongly recommend using knitr’s include_graphics() functions within code chunks to include images or gifs within your blog. This makes it easier to modify figures, add captions and links, and visually find the code for figures quickly if you need to modify something about the output. There is also markdown syntax to display or embed images, but I would typically not recommend it.\n\n\n\n\n\n\n\n\n\nImage courtesy of giphy.com\n\n\n\n\nEither approach will take either a filepath to a stored file or a URL to an image or gif. Width can be specified as a percentage of the width of the page (0% to 100%; my preferred approach) or as a fixed number of units (e.g. 400px, 3in, 10cm).\nI can’t imagine a scenario where students should or would include videos within their blog, but Quarto provides guidance on embedding videos, as well.\n\n\n\n\n\n\nNote\n\n\n\nThe first figure of your blog will be used as the display image on our course’s landing page!"
  },
  {
    "objectID": "index.html#panel-tabsets",
    "href": "index.html#panel-tabsets",
    "title": "Which NESCAC Reigns Supreme?",
    "section": "Panel tabsets",
    "text": "Panel tabsets\nUse the following format to add information or tables or visualizations in tabset panels.\n\nTab 1Tab 2\n\n\nSome information in one tab\n\n\nSome information in a different tab"
  },
  {
    "objectID": "index.html#panel-layouts-for-content",
    "href": "index.html#panel-layouts-for-content",
    "title": "Which NESCAC Reigns Supreme?",
    "section": "Panel layouts for content",
    "text": "Panel layouts for content\nUse the following format to have more control over the panel layout of various components.\nThe syntax “[ [1], [1,1] ]” indicates that we have three pieces of content that we want to spread across two rows. The first piece of content will be in its own row, and then the next two components will be split across two columns of equal width in a second row.\n\n\n\n\n\n\nRow 1 with only one output\nSome content\n\n\n\n\nFirst column of row 2\nSome other content\n\n\nSecond column of row 2\nSome additional content.\n\n\n\nThe values provided within each row specify the relative widths of the content within that row. For example “[1,2,1]” would create a row with 3 columns where the first and third columns are the same width and the middle column is twice as wide."
  },
  {
    "objectID": "index.html#layouts-for-tables-and-visualizations-produced-by-code-chunks",
    "href": "index.html#layouts-for-tables-and-visualizations-produced-by-code-chunks",
    "title": "Which NESCAC Reigns Supreme?",
    "section": "Layouts for tables and visualizations produced by code chunks",
    "text": "Layouts for tables and visualizations produced by code chunks\nFor details on how to layout subfigures from multiple graphs produced by the same code chunk, see the examples in the Knitr tabs of the sections on figure layouts, subcaptions, and custom layouts.\nThe same syntax shown across the linked examples can be used to create subtables by replacing fig-cap and fig-subcap with tbl-cap and tbl-subcap.\nTwo examples in Table 1 and Figure 1 below are borrowed and slightly modified from the linked sections.\n\n\n\nTable 1: Two tables side-by-side\n\n\n\n\n\n\n\n(a) First three rows of cars dataset\n\n\n\n\n\nspeed\ndist\n\n\n\n\n4\n2\n\n\n4\n10\n\n\n7\n4\n\n\n\n\n\n\n\n\n\n\n\n(b) First three rows of pressure dataset\n\n\n\n\n\ntemperature\npressure\n\n\n\n\n0\n0.0002\n\n\n20\n0.0012\n\n\n40\n0.0060\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) cars\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n(b) pressure\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c) mtcars\n\n\n\n\n\n\n\nFigure 1: Three figures in a complex layout"
  },
  {
    "objectID": "yet-another-page.html",
    "href": "yet-another-page.html",
    "title": "Website title",
    "section": "",
    "text": "This is yet another page that can be linked! You are not required to include more than just index.qmd, but you are welcome to make content on different pages, if desired. This may help with managing GitHub commits, as well."
  },
  {
    "objectID": "yet-another-page.html#sec-note",
    "href": "yet-another-page.html#sec-note",
    "title": "Website title",
    "section": "A note",
    "text": "A note\nNotice that you can also modify the YAML headings at the top of each page as I did in the first subpage or completely delete them, as I did here."
  },
  {
    "objectID": "our-work/scraping.html",
    "href": "our-work/scraping.html",
    "title": "scraping",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "our-work/scraping.html#quarto",
    "href": "our-work/scraping.html#quarto",
    "title": "scraping",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "our-work/scraping.html#running-code",
    "href": "our-work/scraping.html#running-code",
    "title": "scraping",
    "section": "Running Code",
    "text": "Running Code\nWhen you click the Render button a document will be generated that includes both content and the output of embedded code. You can embed code like this:\n\n\nparsing URLs on page 1...\nparsing URLs on page 2...\nparsing URLs on page 3...\nparsing URLs on page 4...\nparsing URLs on page 5...\nparsing URLs on page 6...\nparsing URLs on page 7...\nparsing URLs on page 8...\nparsing URLs on page 9...\nparsing URLs on page 10...\n\n\nYou can add options to executable code like this\n\n\n[1] 4\n\n\nThe echo: false option disables the printing of code (onlyndefined output is displayed)."
  },
  {
    "objectID": "Sentiment-analysis.html",
    "href": "Sentiment-analysis.html",
    "title": "Sentiment Analysis ANOVAs",
    "section": "",
    "text": "What’s engagement and sentiment like across subreddits?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 1: Subreddit sentiment & engagement\n\n\n\n\n\n\nSubreddit\nPost Count\nScore (tot)\nComments (tot)\nScore (avg)\nComments (avg)\n\n\n\n\nAmherst College\n521\n2740\n2290\n5.26\n4.40\n\n\nMiddlebury College\n675\n1988\n1594\n2.95\n2.36\n\n\nWilliams College\n622\n2991\n3908\n4.81\n6.28\n\n\n\n\n\n\n\n\n\n\nLet’s compare the subreddits! Table 1 above shows the summary statistics for each subreddit. The values were found by grouping our scraped, sentiment-annotated datasetby subreddit and calculating sums and averages of post count, comment count, and sentiment score. If you want to explore the data further to see how this table came to be check out the full dataset here. The total post counts were comparable, which is what we expected given their similar ages. For sentiment, Middlebury clearly seems stands out as more negative (2.95/post) compared to Amherst (5.26) and Williams (4.81). Amherst and Williams also tend to have higher engagement: 4.40 and 6.28 respectively relative to Midd (2.36). These numbers are fun to compare, but, to assess the statistical significance of these potential differences, you have to go a few steps further.\nSince we were trying to compare the per-post averages of each subreddit on sentiment and engagement, an ANOVA test made sense to use. This statistical test can indicate whether or not one or more pairs of groups differ significantly on average for any quantitative variable, exactly what you would want for our purposes here. Unfortunately, ANOVA is a parametric test, which means you have to check a few important assumptions regarding the characteristics of your data prior to any inference. We won’t get too in the weeds on this blog, but see this PennState “Assumptions for one-way ANOVA test” (n.d.) article if you are curious to learn more. To sum up, any ANOVA test assumes normality, which means your data, which in our case means sentiment and comment counts for each subreddit, looks approximately like this:\n\n\n\n\n\n\n\n\n\nWe fit a two one way ANOVA models to our dataset, one to test for statiscially significant differences between the average sentiment score of each subreddit, and one to compare the average comment counts per post. The results, see TABLE, indicated there was a least one pairwise difference between subreddit post sentiment average (p &lt; 0.001) and comment count (p &lt; 0.001). For more information about what an analysis of variance is doing under the hood, a good reference is provided by Kenton (2024). The logical follow up was to conduct a post-hoc Tukey’s Honestly Significant Difference (HSD), which assess differences between each pair of subreddit means.\nThe results, see TABLE, were conclusive! Each row in the table above holds the results of a Tukey’s HSD comparison between two college subreddits; we colored each row by the college that, according to the test, was deemed to have a significantly higher average (purple for Amherst, gold for Williams, and white for a ‘tie’). Both Amherst (p &lt; 0.001) and Williams (p &lt; 0.001) held a significantly higher average sentiment score per post over Middlebury. Notably, Amherst and Williams did not differ signifcantly by this same metric (p = 0.56). As far as engagement goes, Amherst (p &lt; 0.001) and Williams (p &lt; 0.001) yet again out-performed Middlebury in average comments per post, while Williams convincingly exceeded the mean of Amherst as well (p &lt; 0.001). Again, for more information on the gritty details involved in performing Tukey’s HSD, see this valuable resource, which was helpful for the work present here: Lane (n.d.). Unfortunately gold holds the majority of victories in these pairwise comparisons, and Williams emerges as the champion of this competition by tying Amherst in post positivity and edging us in post engagement. We wish we could fudge the numbers but that would be statistical malpractice.\n\n\n\n\n\nReferences\n\n“Assumptions for one-way ANOVA test” (n.d.).\n\n\nKenton, W. (2024), “What is analysis of variance (ANOVA)?” Investopedia.\n\n\nLane, D. (n.d.). “Tukey’s honestly significant difference (HSD),” Encyclopedia of Research Design."
  },
  {
    "objectID": "another-page.html#amherst-college",
    "href": "another-page.html#amherst-college",
    "title": "Term Frequency - Inverse Document Frequency Analysis",
    "section": "Amherst College",
    "text": "Amherst College\nThe most important TF-IDF keyword is “amherst’s”, as it stands for the strong link that such posts share with the local institutional discussions. Other important ones such as “umass,” “statistics,” and “sem” (probably an abbreviation of “seminar” or “semester”) imply that academic conversations are key. Terms such as “soccer” and “paper” refer both to co-curricular and to course-related subjects. Thus, this combination of academic and student life language demonstrates full engagement with the integral and daily aspects of Amherst as one institution."
  },
  {
    "objectID": "another-page.html#middlebury-college",
    "href": "another-page.html#middlebury-college",
    "title": "Term Frequency - Inverse Document Frequency Analysis",
    "section": "Middlebury College",
    "text": "Middlebury College\nThe notable term in this context is “midd,” an abbreviation for Middlebury known by its community; its high TF-IDF suggests great internal use of the term that could not be so much outside the school. Other terms such as “Vermont,” “MIIS” (Middlebury Institute of International Studies), and “immersion” point toward the institution’s linguistic offerings and geographical flavor. These terms, therefore, become important to denote a subreddit that is exploring local culture, international academic ventures, and even the branding of the university."
  },
  {
    "objectID": "another-page.html#williams-college",
    "href": "another-page.html#williams-college",
    "title": "Term Frequency - Inverse Document Frequency Analysis",
    "section": "Williams College",
    "text": "Williams College\nThe Williams subreddit is about “williamstown,” the town of Williams, so it is likely they talk much more about its location. Terms such as “loci” (probably an abbreviation for “Letter of Continued Interest”), “supplement,” and “previews” indicate a high level of involvement with the admissions procedure. The existence of “ephs” (the mascot of Williams). The subreddit seems to be very busy throughout the admissions period and centered on unique community slang and customs."
  },
  {
    "objectID": "tf-idf.html",
    "href": "tf-idf.html",
    "title": "Term Frequency - Inverse Document Frequency Analysis",
    "section": "",
    "text": "Term Frequency-Inverse Document Frequency (TF-IDF) is a measure of how important a word is in a document, adjusted for the fact that some words appear more frequently in general. In colloquial terms, the TF-IDF of a word is high when it appears frequently in a document but rarely in the corpus (collection of all documents)."
  },
  {
    "objectID": "tf-idf.html#amherst-college",
    "href": "tf-idf.html#amherst-college",
    "title": "Term Frequency - Inverse Document Frequency Analysis",
    "section": "Amherst College",
    "text": "Amherst College\nThe most important TF-IDF keyword is “amherst’s”, as it stands for the strong link that such posts share with the local institutional discussions. Other important ones such as “umass,” “statistics,” and “sem” (probably an abbreviation of “seminar” or “semester”) imply that academic conversations are key. Terms such as “soccer” and “paper” refer both to co-curricular and to course-related subjects. Thus, this combination of academic and student life language demonstrates full engagement with the integral and daily aspects of Amherst as one institution."
  },
  {
    "objectID": "tf-idf.html#middlebury-college",
    "href": "tf-idf.html#middlebury-college",
    "title": "Term Frequency - Inverse Document Frequency Analysis",
    "section": "Middlebury College",
    "text": "Middlebury College\nThe notable term in this context is “midd,” an abbreviation for Middlebury known by its community; its high TF-IDF suggests great internal use of the term that could not be so much outside the school. Other terms such as “Vermont,” “MIIS” (Middlebury Institute of International Studies), and “immersion” point toward the institution’s linguistic offerings and geographical flavor. These terms, therefore, become important to denote a subreddit that is exploring local culture, international academic ventures, and even the branding of the university."
  },
  {
    "objectID": "tf-idf.html#williams-college",
    "href": "tf-idf.html#williams-college",
    "title": "Term Frequency - Inverse Document Frequency Analysis",
    "section": "Williams College",
    "text": "Williams College\nThe Williams subreddit is about “williamstown,” the town of Williams, so it is likely they talk much more about its location. Terms such as “loci” (probably an abbreviation for “Letter of Continued Interest”), “supplement,” and “previews” indicate a high level of involvement with the admissions procedure. The existence of “ephs” (the mascot of Williams). The subreddit seems to be very busy throughout the admissions period and centered on unique community slang and customs."
  },
  {
    "objectID": "time-series.html",
    "href": "time-series.html",
    "title": "Time Series",
    "section": "",
    "text": "For this analysis, we categorized posts by their date into the four quarters of the year: Q1 (January, February, March), Q2 (April, May, June), Q3 (July, August, September) and Q4 (October, November, December). We then calculated the average point value and total point value for the quarter as necessary.\nWhen should I focus on total value versus average value?\nThe total value gives the magnitude of subreddit performance per quarter. Averages represent the central tendency of the quarter, showing the typical post performance per quarter.\nHere are a few tips for interpreting total and average in conjunction for our engagement analyses:\nHigher total + lower average -&gt; more posts but less discussion per post\nHigher average + lower total -&gt; fewer posts but each one sparks more discussion\n\n\nUsing the AFINN Lexicon, which assigns valence per word from -5 (negative) to 5 (positive)\n\n\n\n\n\n\nSentiments in the Amherst subreddit fluctuate greatly from 20202-2022, level out around 2022-2024, and rise in recent years. Middlebury’s subreddit has the lowest sentiment score in general :(. The Williams subreddit has consistently had sentiment scores from 3-7, indicating general positivity in the community. For all three subreddits, there is an recent upward trend in sentiment score, indicating that more people might be interested in liberal arts colleges.\nNevertheless, are these results conclusive? We recommend you head over to our ANOVA results ANOVA results to see if these differences are significant.\n\n\n\nCalculating the number of comments per quarter\n\nTotalAverage\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThere has been a recent increase in the number of total comments each quarter, with an increase starting around 2024 for all three colleges. This indicates that more students and prospective students are using Reddit than previously to connect with each respective college community.\nIn 2024 Q2, there was a sharp increase in the total and average comments in the Williams subreddit. This corresponds to an increase in posts related to college decisions, with a large number of posts during that period being from prospective students asking questions about Williams. One of these posts received a total of 78 comments.\nAround that same time, there was an increase in the average comments per post in the Middlebury subreddit, also corresponding to an increase in posts asking questions about Middlebury.\nIn 2024 Q4, the total number of quarterly comments posted the Amherst subreddit peaked. Around this time, Amherst early decisions were released, with many mixed feelings. Some students posted to connect with other admitted students in the comments, many were rejected, and a many asked questions about their financial aid package.\n\n\n\nCalculating the number of keywords per quarter\nTo analyze subreddit activity related to college applications, we created a custom vector of keywords related to college admissions and then calculated the total and average frequency of these words per quarter.\n\napplication_keywords &lt;- c(\n  \"waitlist\",  \"waitlisted\", \"waitlisting\",\n  \"accept\",    \"accepted\",   \"acceptance\",\n  \"apply\",     \"applied\",    \"applying\", \n  \"application\", \"admission\", \"admissions\",\n  \"defer\",     \"deferred\",   \"deferral\",\n  \"reject\",    \"rejected\",   \"rejection\",\n  \"enroll\",    \"enrolled\",   \"enrollment\",  \n  \"matriculate\", \"matriculated\", \"stats\")\n\n\nTotalAverage\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThere are consistent spikes around Q4 (October, November, December) for all subreddits, which coincide with the peak of college application season. There are also consistent dips around Q1 (April, May, June) when highschool seniors have already decided on a college to attend."
  },
  {
    "objectID": "time-series.html#college-application-keywords",
    "href": "time-series.html#college-application-keywords",
    "title": "Time Series",
    "section": "College Application Keywords",
    "text": "College Application Keywords\nTo analyze subreddit activity related to college applications, we created a custom vector of keywords related to college admissions and then calculated the total and average frequency of these words per quarter.\n\napplication_keywords &lt;- c(\n  \"waitlist\",  \"waitlisted\", \"waitlisting\",\n  \"accept\",    \"accepted\",   \"acceptance\",\n  \"apply\",     \"applied\",    \"applying\", \n  \"application\", \"admission\", \"admissions\",\n  \"defer\",     \"deferred\",   \"deferral\",\n  \"reject\",    \"rejected\",   \"rejection\",\n  \"enroll\",    \"enrolled\",   \"enrollment\",  \n  \"matriculate\", \"matriculated\", \"stats\")\n\n\nTotalAverage\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThere are consistent spikes around Q4 (October, November, December) for all subreddits, which coincide with the peak of college application season. There are also consistent dips around Q1 (April, May, June) when highschool seniors have already decided on a college to attend."
  },
  {
    "objectID": "time-series.html#engagement-through-comments-panel-tabset",
    "href": "time-series.html#engagement-through-comments-panel-tabset",
    "title": "Time Series",
    "section": "",
    "text": ":::"
  },
  {
    "objectID": "time-series.html#sentiments",
    "href": "time-series.html#sentiments",
    "title": "Time Series",
    "section": "",
    "text": "Using the AFINN Lexicon, which assigns valence per word from -5 (negative) to 5 (positive)\n\n\n\n\n\n\nSentiments in the Amherst subreddit fluctuate greatly from 20202-2022, level out around 2022-2024, and rise in recent years. Middlebury’s subreddit has the lowest sentiment score in general :(. The Williams subreddit has consistently had sentiment scores from 3-7, indicating general positivity in the community. For all three subreddits, there is an recent upward trend in sentiment score, indicating that more people might be interested in liberal arts colleges.\nNevertheless, are these results conclusive? We recommend you head over to our ANOVA results ANOVA results to see if these differences are significant."
  },
  {
    "objectID": "time-series.html#overall-comment-engagement",
    "href": "time-series.html#overall-comment-engagement",
    "title": "Time Series",
    "section": "",
    "text": "Calculating the number of comments per quarter\n\nTotalAverage\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThere has been a recent increase in the number of total comments each quarter, with an increase starting around 2024 for all three colleges. This indicates that more students and prospective students are using Reddit than previously to connect with each respective college community.\nIn 2024 Q2, there was a sharp increase in the total and average comments in the Williams subreddit. This corresponds to an increase in posts related to college decisions, with a large number of posts during that period being from prospective students asking questions about Williams. One of these posts received a total of 78 comments.\nAround that same time, there was an increase in the average comments per post in the Middlebury subreddit, also corresponding to an increase in posts asking questions about Middlebury.\nIn 2024 Q4, the total number of quarterly comments posted the Amherst subreddit peaked. Around this time, Amherst early decisions were released, with many mixed feelings. Some students posted to connect with other admitted students in the comments, many were rejected, and a many asked questions about their financial aid package."
  },
  {
    "objectID": "time-series.html#college-application-engagement",
    "href": "time-series.html#college-application-engagement",
    "title": "Time Series",
    "section": "",
    "text": "Calculating the number of keywords per quarter\nTo analyze subreddit activity related to college applications, we created a custom vector of keywords related to college admissions and then calculated the total and average frequency of these words per quarter.\n\napplication_keywords &lt;- c(\n  \"waitlist\",  \"waitlisted\", \"waitlisting\",\n  \"accept\",    \"accepted\",   \"acceptance\",\n  \"apply\",     \"applied\",    \"applying\", \n  \"application\", \"admission\", \"admissions\",\n  \"defer\",     \"deferred\",   \"deferral\",\n  \"reject\",    \"rejected\",   \"rejection\",\n  \"enroll\",    \"enrolled\",   \"enrollment\",  \n  \"matriculate\", \"matriculated\", \"stats\")\n\n\nTotalAverage\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThere are consistent spikes around Q4 (October, November, December) for all subreddits, which coincide with the peak of college application season. There are also consistent dips around Q1 (April, May, June) when highschool seniors have already decided on a college to attend."
  }
]